# -*- coding: utf-8 -*-
"""
Created on Sat May 13 08:26:01 2023

@author: tanoh
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import missingno
import streamlit as st
st.set_option('deprecation.showPyplotGlobalUse', False)

#Importattion des librairies de machine learning
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, f1_score, recall_score #, plot_confusion_matrix, plot_roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import RocCurveDisplay
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from imblearn.over_sampling import SMOTE

st.title("Modele")
st.write("Donnees a predire : ")
st.write("### Benign = 0 et Ransomware = 1")



#Fonction qui permet de recuprer l'ensemble des donnees dans le dossier
directory = 'Benign' #Indiquer le nossier qui contient tout les dataset
t = []
for filename in os.listdir(directory):
    f=os.path.join(directory, filename)
    if os.path.isfile(f):
        d = pd.read_csv(f, delimiter=",")
        t.append(d)

dataset = pd.concat(t, sort=False)

#Categorisation des malwares
dataset.iloc[:, -1].replace({'RANSOMWARE_SVPENG':'Ransomware',
                            'BENIGN':'Benign',
                            'RANSOMWARE_WANNALOCKER':'Ransomware'}, inplace=True)

#Conversion de Label en variable numerique
from sklearn.preprocessing import LabelEncoder
Encoder =  LabelEncoder()
Encoder.fit(dataset.iloc[:, -1].astype(str))
dataset.iloc[:, -1] = Encoder.transform(dataset.iloc[:, -1].astype(str))

features = dataset.drop(dataset.iloc[:, [0, 1, 3, 6, 84]], axis=1)
target = dataset.iloc[:, -1]

#Normalisation
scaler = MinMaxScaler()
features_norm = scaler.fit_transform(features)
features_norm_df = pd.DataFrame(features_norm, columns=features.columns)

#Seaparation de nos donnees
X = features_norm_df
y = target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)


#Fonction evalution sur le train
def Evaluation_Metrics(model, X_train, y_train):
    score = f1_score(y_train, model.predict(X_train))
    precision = precision_score(y_train, model.predict(X_train))
    recall = recall_score(y_train, model.predict(X_train))
    st.write(model)
    st.write("Score_f1 :", score)
    st.write("Precision : ", precision)
    st.write("Recall : ", recall)

#Fonction evalution sur le test
def predict_malware(model, X_test):
    y_pred = model.predict(X_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    score = f1_score(y_test, y_pred)
    st.write(model)
    st.write("Score_f1 :", score)
    st.write("Precision : ", precision)
    st.write("Recall : ", recall)
    
 #Matrice de confusion    
# def graph_matrice(model, X_test, y_test):
#     plot_confusion_matrix(model, X_test, y_test, cmap='Blues')
#     plt.title("Matrice de confusion")
#     plt.show()
#     st.pyplot()
  
#Graphe ROC
# def graph_roc(model, X_test, y_test):
#     plot_roc_curve(model, X_test, y_test)
#     plt.title("Courbe ROC")
#     plt.show()
#     st.pyplot()
    
    
#Interface utilisateur streamlit

model_choice = st.sidebar.selectbox("Choississez un modele", ("GradientBoosting", "Arbre de decision", "Random Forest"))

  
if model_choice == "Arbre de decision":
    Mettre_a_echelle = st.checkbox("Mettre a l'echelle avec SMOTE")
    
    if Mettre_a_echelle:
        st.sidebar.write("## Parametres de SMOTE")
        k_neighbors = st.sidebar.slider("K_Neighbors : ", 0, 50, 3, 1)
        sampling_strategy = st.sidebar.slider("Sampling_Strategy : ", 0.0, 1.0, 0.40, 0.1)
        st.write("-"*50)
        X = features_norm_df
        y = target
        sm = SMOTE(k_neighbors=k_neighbors, sampling_strategy=sampling_strategy)

        # Application du SMOTE aux données
        X_res, y_res = sm.fit_resample(X, y)
        X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=15)
        
        st.sidebar.write("#### Parametres de l'arbre de decision")
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        criterion = st.sidebar.selectbox("Critere : ", ("gini", "entropy"))
        dtc = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=5)
        dtc.fit(X_train, y_train)
        st.write("#### Resultat de l'arbre de decision sur le train : ")
        Evaluation_Metrics(dtc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultat de l'arbre de decision sur le test : ")
        predict_malware(dtc, X_test)
            
#         graph_matrice(dtc, X_test, y_test)
#         graph_roc(dtc, X_test, y_test)
            
    else:
        X = features_norm_df
        y = target
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)
        
        st.sidebar.write("#### Parametres de l'arbre de decision")
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        criterion = st.sidebar.selectbox("Critere : ", ("gini", "entropy"))
        dtc = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=5)
        dtc.fit(X_train, y_train)
        st.write("#### Resultat de l'arbre de decision sur le train : ")
        Evaluation_Metrics(dtc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultat de l'arbre de decision sur le test : ")
        predict_malware(dtc, X_test)
            
#         graph_matrice(dtc, X_test, y_test)
#         graph_roc(dtc, X_test, y_test)

   
  
elif model_choice == "Random Forest":
    Mettre_a_echelle = st.checkbox("Mettre a l'echelle avec SMOTE")
    if Mettre_a_echelle:
        st.sidebar.write("## Parametres de SMOTE")
        k_neighbors = st.sidebar.slider("K_Neighbors : ", 0, 50, 3, 1)
        sampling_strategy = st.sidebar.slider("Sampling_Strategy : ", 0.0, 1.0, 0.40, 0.1)
        st.write("-"*50)
        X = features_norm_df
        y = target
        sm = SMOTE(k_neighbors=3, sampling_strategy=0.75)
        
        # Application du SMOTE aux données
        X_res, y_res = sm.fit_resample(X, y)
        X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=15)
        
        st.sidebar.write("### Parametres du Random Forest")
        n_estimators = st.sidebar.slider("Nombre d'estimateurs : ", 1, 100, 100, 1)
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=5)
        rfc.fit(X_train, y_train)
        st.write("#### Resultats du Random Forest sur le train")
        Evaluation_Metrics(rfc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultats du Random Forest sur le test")
        predict_malware(rfc, X_test)
        
#         graph_matrice(rfc, X_test, y_test)
#         graph_roc(rfc, X_test, y_test)
        
    else:
        X = features_norm_df
        y = target
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)
        
        st.sidebar.write("### Parametres du Random Forest")
        n_estimators = st.sidebar.slider("Nombre d'estimateurs : ", 1, 100, 100, 1)
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=5)
        rfc.fit(X_train, y_train)
        st.write("#### Resultats du Random Forest sur le train")
        Evaluation_Metrics(rfc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultats du Random Forest sur le test")
        predict_malware(rfc, X_test)
        
#         graph_matrice(rfc, X_test, y_test)
#         graph_roc(rfc, X_test, y_test)
    
else :
    Mettre_a_echelle = st.checkbox("Mettre a l'echelle avec SMOTE")
    if Mettre_a_echelle:
        st.sidebar.write("## Parametres de SMOTE")
        k_neighbors = st.sidebar.slider("K_Neighbors : ", 0, 50, 3, 1)
        sampling_strategy = st.sidebar.slider("Sampling_Strategy : ", 0.0, 1.0, 0.40, 0.1)
        st.write("-"*50)
        X = features_norm_df
        y = target
        sm = SMOTE(k_neighbors=3, sampling_strategy=0.75)
        
        # Application du SMOTE aux données
        X_res, y_res = sm.fit_resample(X, y)
        X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=15)
        st.sidebar.write("### Parametres du GradientBoosting")
        n_estimators = st.sidebar.slider("Nombre d'estimateurs : ", 1, 100, 100, 1)
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        learning_rate = st.sidebar.slider("Learning_rate : ", 0.0, 100.0, 0.1, 0.1)
        criterion = st.sidebar.selectbox("Critere : ", ("friedman_mse", "squared_error"))
        Gbc = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion, learning_rate=learning_rate, random_state=5)
        Gbc.fit(X_train, y_train)
        st.write("#### Resultats du GradientBoostingClassifier sur le train")
        Evaluation_Metrics(Gbc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultats du GradientBoostingClassifier sur le test")
        predict_malware(Gbc, X_test)
        
#         graph_matrice(Gbc, X_test, y_test)
#         graph_roc(Gbc, X_test, y_test)
        
    else:
        X = features_norm_df
        y = target
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)
        
        st.sidebar.write("### Parametres du GradientBoosting")
        n_estimators = st.sidebar.slider("Nombre d'estimateurs : ", 1, 100, 100, 1)
        max_depth = st.sidebar.slider("Profondeur maximale : ", 1, 50, 5, 1)
        learning_rate = st.sidebar.slider("Learning_rate : ", 0.0, 100.0, 0.1, 0.1)
        criterion = st.sidebar.selectbox("Critere : ", ("friedman_mse", "squared_error"))
        Gbc = GradientBoostingClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion, learning_rate=learning_rate, random_state=5)
        Gbc.fit(X_train, y_train)
        st.write("#### Resultats du GradientBoostingClassifier sur le train")
        Evaluation_Metrics(Gbc, X_train, y_train)
        st.write("-"*100)
        st.write("#### Resultats du GradientBoostingClassifier sur le test")
        predict_malware(Gbc, X_test)
        
#         graph_matrice(Gbc, X_test, y_test)
#         graph_roc(Gbc, X_test, y_test)
        
    
    


